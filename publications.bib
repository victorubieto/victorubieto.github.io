@techReport{Murtagh2022,
   abstract = {Natural language processing and the machine translation of spoken language (speech/text) has benefitted from significant scientific research and development in recent times, rapidly advancing the field. On the other hand, computational processing and modelling of signed language has unfortunately not garnered nearly as much interest, with sign languages generally being excluded from modern language technologies. Many deaf and hard-of-hearing individuals use sign language on a daily basis as their first language. For the estimated 72 million deaf people in the world, the exclusion of sign languages from modern natural language processing and machine translation technology, aggravates further the communication barrier that already exists for deaf and hard-of-hearing individuals. This research leverages a linguistically informed approach to the processing and modelling of signed language. We outline current challenges for sign language machine translation from both a linguistic and a technical prespective. We provide an account of our work in progress in the development of sign language lexicon entries and sign language lexeme repository entries for SLMT. We leverage Role and Reference Grammar together with the Sign_A computational framework within this development. We provide an XML description for Sign_A, which is utilised to document SL lexicon entries together with SL lexeme repository entries. This XML description is also lev-eraged in the development of an extension to Bahavioural Markup Language, which will be used within this development to link the divide between the sign language lexicon and the avatar animation interface.},
   author = {Irene Murtagh and Víctor Ubieto and Josep Blat},
   title = {Sign Language Machine Translation and the Sign Language Lexicon: A Linguistically In-formed Approach},
   url = {https://signon-project.eu},
   year = {2022}
}
@inbook{Ubieto2024,
   abstract = {Animating avatars for sign languages (SLs) is a challenging task due to the high quality and naturalness requirements. Recent publications and media show that virtual avatar quality is evolving, yet remain greatly constrained by the predefined set of animations available, crafted by skillful animators. In this research, we propose two different but complementary systems, focusing on sign animations synthesis and scalability. The first uses Behaviour Markup Language (BML) to drive the avatar procedurally from textual instructions, derived from HamNoSys, SiGML and the Facial Action Coding System (FACS). Several techniques are employed for driving the avatar such as geometric inverse kinematics and blendshape weight modulation. The second system resorts on widespread low-end technology such as webcams to generate 3D animations from simple video by applying different Machine Learning (ML) techniques. In our implementation, both systems are coupled with an editor for tweaking the resulting 3D animations. It also provides a point-and-click interface for generating BMLs through sliders and boxes that can be greatly adjusted in time and duration. Hence, users can generate new content adapted to their circumstances without the need of specialised equipment or knowledge.},
   author = {Víctor Ubieto and Jaume Pozo and Eva Valls and Beatriz Cabrero-Daniel and Josep Blat},
   city = {Cham},
   doi = {10.1007/978-3-031-47362-3_10},
   editor = {Lorraine
and Shterionov Dimitar Way Andy
and Leeson},
   isbn = {978-3-031-47362-3},
   booktitle = {Sign Language Machine Translation},
   pages = {247-266},
   publisher = {Springer Nature Switzerland},
   title = {Sign Language Synthesis: Current Signing Avatar Systems and Representation},
   volume = {5},
   url = {https://doi.org/10.1007/978-3-031-47362-3_10},
   year = {2024}
}
